# ğŸ¤ Integrated Meeting Transcription & Speaker Identification System

Há»‡ thá»‘ng tá»± Ä‘á»™ng ghi chÃ©p biÃªn báº£n há»p tá»« file audio
## ğŸ“‹ Output Máº«u

```
[00:05] khoa: Xin chÃ o má»i ngÆ°á»i, chÃºng ta báº¯t Ä‘áº§u cuá»™c há»p
[00:12] an: TÃ´i Ä‘á»“ng Ã½, bÃ¢y giá» lÃ  2 giá» chiá»u
[00:18] binh: HÃ´m nay chÃºng ta tháº£o luáº­n gÃ¬?
[00:25] khoa: ChÃºng ta sáº½ nÃ³i vá» dá»± Ã¡n má»›i
```

---

## ğŸš€ Quick Start

### âš ï¸ Requirements

- **Python**: 3.9, 3.10, 3.11, hoáº·c 3.12 (recommended: **3.12.6**)
- **RAM**: Tá»‘i thiá»ƒu 8GB (khuyÃªn 16GB+)
- **Disk**: 20GB+ (Ä‘á»ƒ download models)
- **GPU** (optional): NVIDIA GPU + CUDA 12.1 (tÄƒng tá»‘c Ä‘á»™ 10x)

### 1. Kiá»ƒm tra phiÃªn báº£n Python

```powershell
python --version
# Output: Python 3.10.x hoáº·c 3.11.x
```

Náº¿u chÆ°a cÃ i hoáº·c phiÃªn báº£n sai:
- Download tá»«: https://www.python.org/downloads/
- Chá»n **Python 3.11 hoáº·c 3.12**
- âœ… Tick: "Add Python to PATH"

### 2. CÃ i Äáº·t Dependencies

```bash
# Clone/download project
cd meeting_ai

# Cáº­p nháº­t pip, setuptools, wheel
python -m pip install --upgrade pip setuptools wheel

# CÃ i Ä‘áº·t tá»« requirements.txt
pip install -r requirements.txt
```


### 3. Chuáº©n Bá»‹ Speaker Samples

Táº¡o thÆ° má»¥c `speaker_samples/` chá»©a file audio enroll:
```
speaker_samples/
  khoa.wav          (hoáº·c khoa_1.wav, khoa_2.wav, ...)
  khoa_meeting.wav
  an.wav
  an_1.wav
  binh.wav
  binh_2.wav
```

**Quy táº¯c**: TÃªn file = `{tÃªn_ngÆ°á»i}[_sá»‘].{ext}`
- âœ… `alice.wav` â†’ Speaker: "alice"
- âœ… `alice_1.wav` â†’ Speaker: "alice"
- âœ… `bob_sample.wav` â†’ Speaker: "bob"

Má»—i speaker cáº§n: **1-3 file, má»—i file 5-10 giÃ¢y ghi Ã¢m**

### 4. Láº¥y HuggingFace Token

1. ÄÄƒng kÃ½: https://huggingface.co
2. Accept license: https://huggingface.co/pyannote/speaker-diarization-3.1
3. Táº¡o token: https://huggingface.co/settings/tokens

### 5. Download pretrained models
```powershell
git clone https://huggingface.co/kho4h2utr4n/meeting-ai-pretrained-models
```

### 6. Cháº¡y

```powershell
# Set token (Windows PowerShell)
$env:HF_TOKEN='hf_xxxxxxxxxxxxx'

# Enroll speakers (láº§n Ä‘áº§u)
python integrated_meeting_system.py enroll .\speaker_samples

# Process meeting
python integrated_meeting_system.py process .\meeting.wav .\speaker_samples vi
```

---

## ğŸ“š Cáº¥u TrÃºc Project

```
meeting_ai/
â”œâ”€â”€ integrated_meeting_system.py    # Main entry point (orchestrator)
â”œâ”€â”€ speaker_db.py                   # Database management
â”œâ”€â”€ speaker_recognition.py          # ECAPA-TDNN speaker embedding & identification
â”œâ”€â”€ audio_processor.py              # Audio normalization, loading, extraction
â”œâ”€â”€ transcriber.py                  # WhisperX transcription
â”œâ”€â”€ diarizer.py                     # Pyannote speaker diarization
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ speaker_db/                     # (auto-created) Speaker embeddings
â”‚   â””â”€â”€ speaker_db.pkl
â”œâ”€â”€ speaker_samples/                # Enrollment audio files
â”‚   â”œâ”€â”€ khoa.wav
â”‚   â”œâ”€â”€ an.wav
â”‚   â””â”€â”€ binh.wav
â”œâ”€â”€ pretrained_models/              # Pretrained models
â”‚   â”œâ”€â”€ ecapa-tdnn/
â”‚   â”œâ”€â”€ diarization/
â”‚   â”œâ”€â”€ models--Systran--faster-whisper-large-v2/
â”‚   â””â”€â”€ wav2vec2-base-vi-vlsp2020/
â””â”€â”€ meeting_output/                 # (auto-created) Results
    â”œâ”€â”€ normalized_audio.wav
    â”œâ”€â”€ meeting_transcript_*.json
    â””â”€â”€ meeting_transcript_*.txt
```

---

## ğŸ›ï¸ CLI Commands

### 1. **Process Meeting** (Cháº¡y full pipeline)

```bash
python integrated_meeting_system.py process <audio_file> <enroll_dir> [language]
```

**VÃ­ dá»¥:**
```powershell
python integrated_meeting_system.py process meeting.wav .\speaker_samples vi
python integrated_meeting_system.py process recording.mp3 .\enrollments en
```

**Args:**
- `audio_file`: ÄÆ°á»ng dáº«n file Ã¢m thanh (WAV, MP3, MP4, FLAC, ...)
- `enroll_dir`: ThÆ° má»¥c chá»©a file enroll speakers
- `language` (optional): MÃ£ ngÃ´n ngá»¯ (máº·c Ä‘á»‹nh: "vi")
  - `vi` - Tiáº¿ng Viá»‡t
  - `en` - Tiáº¿ng Anh
  - `fr` - Tiáº¿ng PhÃ¡p

### 2. **Enroll Speakers** (Táº¡o/cáº­p nháº­t database)

```bash
python integrated_meeting_system.py enroll <enroll_dir> [--force]
```

**VÃ­ dá»¥:**
```powershell
# Enroll láº§n Ä‘áº§u
python integrated_meeting_system.py enroll .\speaker_samples

# Re-enroll (ghi Ä‘Ã¨ database cÅ©)
python integrated_meeting_system.py enroll .\speaker_samples --force
```

### 3. **List Speakers** (Liá»‡t kÃª ngÆ°á»i Ä‘Æ°á»£c enroll)

```bash
python integrated_meeting_system.py list-speakers
```

**Output:**
```
Enrolled speakers (3):
  - khoa
  - an
  - binh
```

### 4. **Remove Speaker** (XÃ³a 1 speaker)

```bash
python integrated_meeting_system.py remove-speaker <speaker_name>
```

**VÃ­ dá»¥:**
```powershell
python integrated_meeting_system.py remove-speaker khoa
```

### 5. **Clear Database** (XÃ³a toÃ n bá»™)

```bash
python integrated_meeting_system.py clear-db
```

---

## ğŸ“‚ Output Files

Káº¿t quáº£ lÆ°u vÃ o `meeting_output/` (hoáº·c `--output_dir`):

### `meeting_transcript_*.json`
```json
{
  "metadata": {
    "audio_file": "meeting.wav",
    "enrollment_dir": "speaker_samples",
    "language": "vi",
    "timestamp": "2025-01-25T14:30:22.123456",
    "device": "cuda"
  },
  "transcript": [
    {
      "speaker": "khoa",
      "text": "Xin chÃ o má»i ngÆ°á»i",
      "timestamp": "[00:05]",
      "confidence": 0.92
    },
    {
      "speaker": "an",
      "text": "TÃ´i Ä‘á»“ng Ã½",
      "timestamp": "[00:12]",
      "confidence": 0.88
    }
  ],
  "statistics": {
    "total_speakers": 3,
    "total_segments": 42,
    "enrolled_speakers": ["khoa", "an", "binh"]
  }
}
```

### `meeting_transcript_*.txt`
```
[00:05] khoa: Xin chÃ o má»i ngÆ°á»i
[00:12] an: TÃ´i Ä‘á»“ng Ã½
[00:18] binh: HÃ´m nay chÃºng ta tháº£o luáº­n gÃ¬?
```

---

## ğŸ Python API (For Developers)

### Import Individual Modules

```python
from speaker_recognition import SpeakerRecognizer
from audio_processor import AudioProcessor
from transcriber import Transcriber
from diarizer import Diarizer
from speaker_db import SpeakerDatabase

# Use modules independently
recognizer = SpeakerRecognizer()
processor = AudioProcessor()
transcriber = Transcriber()
```

### Full Pipeline

```python
from integrated_meeting_system import IntegratedMeetingSystem

# Initialize
system = IntegratedMeetingSystem(huggingface_token="hf_xxxxx")

# Process meeting
result = system.process_meeting(
    audio_path="meeting.wav",
    enroll_dir="speaker_samples",
    output_dir="./output",
    language="vi"
)

# Access results
for item in result["transcript"]:
    print(f"{item['timestamp']} {item['speaker']}: {item['text']}")
```

### Speaker Recognition Only

```python
from speaker_recognition import SpeakerRecognizer
from speaker_db import SpeakerDatabase

# Create database and recognizer
db = SpeakerDatabase(db_dir="./my_db")
recognizer = SpeakerRecognizer(speaker_db=db)

# Enroll speakers
recognizer.enroll_speakers_from_directory("./speaker_samples")

# Identify speaker
speaker, confidence = recognizer.identify("unknown_audio.wav")
print(f"{speaker} (confidence: {confidence:.2f})")

# List enrolled
print(recognizer.get_enrolled_speakers())

# Remove speaker
recognizer.remove_speaker("khoa")
```

### Audio Processing Only

```python
from audio_processor import AudioProcessor

processor = AudioProcessor(target_sr=16000)

# Normalize audio
normalized = processor.normalize_audio("input.mp3", "output.wav")

# Get info
info = processor.get_audio_info("audio.wav")
print(f"Duration: {info['duration_seconds']}s")

# Load and resample
waveform, sr = processor.load_audio("audio.wav")
```

---

## âš™ï¸ Configuration & Tuning

### 1. **NgÃ´n Ngá»¯ ASR**

Thay Ä‘á»•i parameter `language`:
```powershell
# Tiáº¿ng Viá»‡t (default)
python integrated_meeting_system.py process audio.wav samples vi

# Tiáº¿ng Anh
python integrated_meeting_system.py process audio.wav samples en

# Tiáº¿ng PhÃ¡p
python integrated_meeting_system.py process audio.wav samples fr
```

### 2. **Device (GPU/CPU)**

Script tá»± Ä‘á»™ng detect GPU. Äá»ƒ force CPU:
```python
system = IntegratedMeetingSystem(
    huggingface_token="...",
    device="cpu"  # hoáº·c "cuda"
)
```

### 3. **Speaker Recognition Threshold**

Äiá»u chá»‰nh trong `speaker_recognition.py`:
```python
# Máº·c Ä‘á»‹nh: 0.25 (cosine similarity)
# TÄƒng â†’ cháº·t hÆ¡n (Ã­t false positive)
# Giáº£m â†’ lá»ng hÆ¡n (Ã­t false negative)

speaker, score = recognizer.identify("audio.wav", threshold=0.30)
```

### 4. **Model Size**

Thay Ä‘á»•i WhisperX model:
```python
transcriber = Transcriber(model_size="large-v2")  # máº·c Ä‘á»‹nh
# hoáº·c: "base", "small", "medium", "large"
```

---

## ğŸ”§ Troubleshooting

### âŒ "HuggingFace token not provided"
```powershell
# Windows PowerShell
$env:HF_TOKEN='hf_xxxxxxxxxxxxx'

# Hoáº·c thÃªm vÃ o PowerShell profile
Add-Content $PROFILE "`n`$env:HF_TOKEN='hf_xxxxx'"
```

### âŒ "CUDA out of memory"
```python
system = IntegratedMeetingSystem(
    huggingface_token="...",
    device="cpu"  # DÃ¹ng CPU thay vÃ¬ GPU
)
```

### âŒ "No speech detected"
- Kiá»ƒm tra volume audio (quÃ¡ yáº¿u)
- DÃ¹ng FFmpeg Ä‘á»ƒ tÄƒng volume:
  ```bash
  ffmpeg -i input.wav -af "volume=2.0" output.wav
  ```

### âŒ "Speaker not recognized (Unknown)"
- Enrollment samples chÆ°a tá»‘t â†’ ghi thÃªm audio
- Threshold quÃ¡ cao â†’ háº¡ tá»« 0.25 â†’ 0.20
- Audio quality kÃ©m â†’ xá»­ lÃ½ audio trÆ°á»›c

### âŒ "Transcription accuracy low"
- WhisperX large-v2 tá»‘i Æ°u cho tiáº¿ng Anh
- Tiáº¿ng Viá»‡t cÃ³ thá»ƒ kÃ©m chÃ­nh xÃ¡c
- Solution: Fine-tune hoáº·c dÃ¹ng ASR tiáº¿ng Viá»‡t khÃ¡c

### âŒ Diarization sai
- Giáº£m sá»‘ speakers â†’ tÄƒng `distance_threshold`
- TÄƒng sá»‘ speakers â†’ giáº£m `distance_threshold`
- Enrollment samples Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ improve diarization

---

## ğŸ“Š Performance

| ThÃ nh pháº§n | Thá»i gian (GPU) | Thá»i gian (CPU) |
|-----------|-----------------|-----------------|
| Audio 1 phÃºt | 2-5 phÃºt | 10-20 phÃºt |
| Audio 1 giá» | 30-60 phÃºt | 2-4 giá» |
| Enroll 1 speaker (5 files) | 10-20s | 30-60s |

**Láº§n Ä‘áº§u**: +10 phÃºt (download models ~10GB)

---

## ğŸ“ Models Used

| Model | Nguá»“n | KÃ­ch ThÆ°á»›c | Chá»©c NÄƒng |
|-------|--------|----------|-----------|
| **WhisperX large-v2** | OpenAI | 3GB | ASR (Speech-to-Text) |
| **Pyannote 3.1** | Meta | 1.5GB | Diarization |
| **ECAPA-TDNN** | SpeechBrain | 150MB | Speaker Embedding |

---

## âš ï¸ Limitations

- âŒ WhisperX large-v2 optimized cho tiáº¿ng Anh â†’ Tiáº¿ng Viá»‡t cÃ³ kÃ©m chÃ­nh xÃ¡c
- âŒ Diarization khÃ´ng hoÃ n háº£o trong mÃ´i trÆ°á»ng ráº¥t á»“n
- âŒ Speaker recognition phá»¥ thuá»™c cháº¥t lÆ°á»£ng enrollment samples
- âŒ KhÃ´ng support real-time processing (batch processing)

---

## ğŸ“ License

MIT

---

## ğŸ¤ Contributing

Contributions welcome! CÃ¡c hÆ°á»›ng cáº£i thiá»‡n:
1. Fine-tune ASR cho tiáº¿ng Viá»‡t
2. Cáº£i thiá»‡n diarization trong mÃ´i trÆ°á»ng á»“n
3. Support thÃªm ngÃ´n ngá»¯
4. Real-time processing support
5. Web UI

---

## ğŸ“§ Support

CÃ³ váº¥n Ä‘á»? HÃ£y:
1. Kiá»ƒm tra Troubleshooting section
2. Äáº£m báº£o cÃ i Ä‘áº·t Ä‘Ãºng dependencies
3. Kiá»ƒm tra format file audio
4. Kiá»ƒm tra HuggingFace token há»£p lá»‡

---

## ğŸ¯ Next Steps

1. âœ… CÃ i Ä‘áº·t & chuáº©n bá»‹ data
2. âœ… Enroll speakers
3. âœ… Cháº¡y trÃªn file test
4. ğŸ”„ Tinh chá»‰nh parameters
5. ğŸ“Š Evaluate káº¿t quáº£
6. ğŸš€ Deploy production

---

**Happy transcribing! ğŸ‰**
